{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "Task: Obtain the 200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the [details page](https://www.topuniversities.com/universities/ecole-polytechnique-fédérale-de-lausanne-epfl).\n",
    "Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "- Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "- Answer the previous question aggregating the data by (c) country and (d) region.\n",
    "\n",
    "Plot your data using bar charts and describe briefly what you observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of top universities to take into consideration throughout the process\n",
    "n_top = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'https://www.topuniversities.com'\n",
    "ranking_url = 'https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detail_keys = ['total faculty', 'inter faculty', 'total student', 'total inter']\n",
    "\n",
    "#From  a String, extract only the digits and return as an int\n",
    "def extract_int(s):\n",
    "    return int(''.join(c for c in s if c.isdigit()))\n",
    "\n",
    "# Get the details of a uni from the details page and return a dictionary containing the values for the 4 above keys\n",
    "def get_topU_details(uni_url):\n",
    "    details_url = base_url + uni_url\n",
    "    \n",
    "    r = requests.get(details_url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    # Find the divs containing the numbers in the html page\n",
    "    divs = [soup.find('div', detail_key) for detail_key in detail_keys]\n",
    "    divs = [div.find('div', class_='number') if div != None else None for div in divs]\n",
    "    numbers = [extract_int(div.text) if div != None else 0 for div in divs]\n",
    "  \n",
    "    #Finally we zip the numbers with their respective key names\n",
    "    details = dict(zip(detail_keys, numbers))\n",
    "    \n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(ranking_url)\n",
    "\n",
    "if(r.status_code != requests.codes.ok):\n",
    "    sys.exit('Could not contact webpage {0}'.format(ranking_url))\n",
    "    \n",
    "rank_data = r.json()[\"data\"][:n_top]\n",
    "\n",
    "#keys we want to extract and keep. We treat ranks differently because we have to do a special operation on them\n",
    "keys = ['title','country','region']\n",
    "\n",
    "country_to_region_map = {}\n",
    "rankings_dico = []\n",
    "for uni in rank_data:    \n",
    "    values = dict([(key, uni[key]) for key in keys if key in uni])\n",
    "    values['rank_display'] = uni['rank_display'].strip(\"=\")\n",
    "    \n",
    "    #Get the details and add them to the values\n",
    "    details = get_topU_details(uni['url'])\n",
    "    values.update(details)\n",
    "    \n",
    "    rankings_dico.append(values)\n",
    "    \n",
    "    # Build the country to region map\n",
    "    country_to_region_map[values['country']] = values['region']\n",
    "\n",
    "# We manually add two countries that are missing and that we need afterwards\n",
    "country_to_region_map['Luxembourg'] = 'Europe'\n",
    "country_to_region_map['Russian Federation'] = 'Asia'\n",
    "\n",
    "rankings = pd.DataFrame(rankings_dico)\n",
    "rankings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computes the two demanded ratios and plots the best universities in a bar chart\n",
    "def plot_top_by_ratio(rankings_df, x_title, x_key='title'):\n",
    "    #Drop any existing ratios if they exist\n",
    "    rankings_df.drop(['ratio_a','ratio_b'], errors='ignore')\n",
    "    \n",
    "    # Create new columns that containthe calculated ratios\n",
    "    rankings_df['ratio_a'] = rankings_df['total faculty'] / rankings_df['total student']\n",
    "    rankings_df['ratio_b'] = rankings_df['total inter'] / rankings_df['total student']\n",
    "\n",
    "    # Sort and keep the top 10\n",
    "    best_a = rankings_df.sort_values(by='ratio_a',ascending=False).head(10)\n",
    "    best_b = rankings_df.sort_values(by='ratio_b',ascending=False).head(10)\n",
    "\n",
    "    # Plot\n",
    "    best_a.plot(kind='bar', x=x_key, y='ratio_a', legend=None, title='Best ' + x_title + ' in term of ratio between faculty members and students')\n",
    "    best_b.plot(kind='bar', x=x_key, y='ratio_b', legend=None, title='Best ' + x_title + ' in term of ratio of international students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_by_ratio(rankings, 'universities', 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe above that the best universities for the described ratios are the California Institute of Technology and the London School of Economis and Political Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We group by country and then give to the function that will recalculate ratios and plot\n",
    "rankings_by_country = rankings.groupby('country').agg(np.sum)\n",
    "rankings_by_country.reset_index(inplace=True) \n",
    "\n",
    "plot_top_by_ratio(rankings_by_country, 'country', 'country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best countries for the described ratios are Russia and Australia, as can be seen in the graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rankings_by_region = rankings.groupby('region').agg(np.sum)\n",
    "rankings_by_region.reset_index(inplace=True) \n",
    "\n",
    "plot_top_by_ratio(rankings_by_region, 'region', 'region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning the regions, the best are Asia and Oceania respectively for the two demanded ratios. The difference of international students ratio between regions is quite large, and the results can be quite surprising: Oceania comes before Europe, and Africa before Asia, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Obtain the 200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)). Repeat the analysis of the previous point and discuss briefly what you observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_ranking_url = 'https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We repeat the same process for the Times ranking\n",
    "times_r = requests.get(times_ranking_url)\n",
    "\n",
    "if(times_r.status_code != requests.codes.ok):\n",
    "    sys.exit('Could not contact webpage {0}'.format(times_ranking_url))\n",
    "    \n",
    "times_rank_data = times_r.json()[\"data\"][:n_top]\n",
    "\n",
    "times_rankings_dico = []\n",
    "for uni in times_rank_data:\n",
    "    values = dict()\n",
    "    values['title'] = uni['name']\n",
    "    values['country'] = uni['location']\n",
    "    values['rank_display'] = uni['rank'].strip(\"=\")\n",
    "    values['region'] = country_to_region_map.get(values['country'], \"Unknown\")\n",
    "    \n",
    "    values['total student'] = extract_int(uni['stats_number_students'])\n",
    "    \n",
    "    values['total inter'] = int(values['total student'] * extract_int(uni['stats_pc_intl_students']) / 100)\n",
    "    values['total faculty'] = values['total student'] * (1.0 / float(uni['stats_student_staff_ratio']))\n",
    "    #we don't need the number of international in the faculty, and can't calculate it anyway\n",
    "    \n",
    "    times_rankings_dico.append(values)\n",
    "\n",
    "times_rankings = pd.DataFrame(times_rankings_dico)\n",
    "times_rankings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_top_by_ratio(times_rankings, 'universities', 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best unis are the Vanderbilt University and the London School of Economis and Political Science. Caltech isn't even in the first top 10, while it was first in the other ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We group by country and then give to the function that will recalculate ratios and plot\n",
    "times_rankings_by_country = times_rankings.groupby('country').agg(np.sum)\n",
    "times_rankings_by_country.reset_index(inplace=True) \n",
    "\n",
    "plot_top_by_ratio(times_rankings_by_country, 'country', 'country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best countries are Denmark and Luxembourg respectively. We see that Luxembourg is by far the first in terms of international students, which can be explained by the small number of total students in the university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rankings_by_region = times_rankings.groupby('region').agg(np.sum)\n",
    "times_rankings_by_region.reset_index(inplace=True) \n",
    "\n",
    "plot_top_by_ratio(times_rankings_by_region, 'region', 'region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best regions are Africa and Oceania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We describe our best method below. We also tried merging using a distance function on the uni names, but the results were less concluant. Please see the end of the notebook for the first method we tried (using distance function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We first merge by exact corresponding uni titles, then look at the remaining ones that haven't been merged.\n",
    "merged_ranking = pd.merge(rankings, times_rankings, how='outer', on='title', indicator=True, suffixes=('_topU', '_times'))\n",
    "\n",
    "#Reorder the columns lexicographically so that corresponding columns are side-by-side for easier comparison\n",
    "merged_ranking.sort_index(axis=1, inplace=True)\n",
    "\n",
    "#print('Number of merged universities: ' + str(len(merged_ranking)) + ' / ' + str(len(rankings)))\n",
    "topU_only = merged_ranking[merged_ranking['_merge'] == 'left_only']\n",
    "times_only = merged_ranking[merged_ranking['_merge'] == 'right_only']\n",
    "both = merged_ranking[merged_ranking['_merge'] == 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# These are the unis from Times that didn't find a perfect match\n",
    "times_only.head()\n",
    "\n",
    "# We can do the same for Top Universities with 'topU_only.head()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that in most cases that were not merged, the uni titles have additional abbreviations, or some characters are a bit different (such as the dash in ETH Zurich). We decide to remove the special characters from the titles, make them all lowercase, and then check if the titles in each dataframe contain each other.\n",
    "\n",
    "We check if one of the normalized titles is contained in another, and if so, we consider it a match. Note that when there are multiple matches, like with 'The Chinese University of Hong Kong (CUHK)' and 'University of Hong Kong', we ignore the match, but this happens only once for all unis. We could additionally compute a difference function between the conflicting matches to resolve the issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a column 'n_title' with a lowercase-only title that was stripped of its special characters and spaces\n",
    "def add_normalize_title(df):\n",
    "    n_titles = df['title']\n",
    "    n_titles = n_titles.str.replace('[^a-zA-Z]', '')\n",
    "    n_titles = n_titles.str.lower()\n",
    "\n",
    "    df['n_title'] = n_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "add_normalize_title(topU_only)\n",
    "add_normalize_title(times_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what the new column looks like\n",
    "topU_only['n_title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This method compares pairs of uni names, and if one of the unis in a pair is contained in the other, it adds\n",
    "# a new row to our merged table 'both'.\n",
    "def find_title_contain(left, right):\n",
    "    global both\n",
    "    for (index_topU,uni_name) in left['n_title'].iteritems():\n",
    "        # create an array of booleans indicating if the uni name is contained in one of the other uni names\n",
    "        contains = right['n_title'].str.contains(uni_name)\n",
    "\n",
    "        # we merge and add the row only if there's an unique match.\n",
    "        if np.sum(contains) == 1:\n",
    "            #print('Found unique match! :D for ' + uni_name)\n",
    "            index_times = contains.index[contains == True].tolist()[0]\n",
    "\n",
    "            topU_part = left.loc[[index_topU]].squeeze().dropna(how='all').drop(['title'])\n",
    "            times_part = right.loc[[index_times]].squeeze().dropna(how='all')\n",
    "\n",
    "            # Create a row with both uni details\n",
    "            joined = topU_part.append(times_part)\n",
    "            joined.drop(['_merge', 'n_title'], inplace=True)\n",
    "\n",
    "            # Add thw row to our big table 'both'\n",
    "            both.loc[-1] = joined\n",
    "            both.reset_index(drop=True,inplace=True)\n",
    "            both = both.drop('_merge',  errors='ignore',axis=1)\n",
    "            \n",
    "            left = left.drop(index_topU)\n",
    "            right = right.drop(index_times)\n",
    "\n",
    "        #elif np.sum(contains) > 1:\n",
    "            #print('Found multiple matches :O for ' + uni_name)\n",
    "       # else:\n",
    "            #print('Found no match :( for ' + uni_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_title_contain(topU_only, times_only)\n",
    "find_title_contain(times_only, topU_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a merged dataframe with details of both websites. We were able to merge 147 universities with our method. As described earlier, we also tried another method that can be found at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "both.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = both.corr()\n",
    "\n",
    "c[c > 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "Can you find the best university taking in consideration both rankings? Explain your approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both['tot_rank'] = pd.to_numeric(both['rank_display_times']) + pd.to_numeric(both['rank_display_topU'])\n",
    "both.sort_values(by='tot_rank')['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexe\n",
    "#### Get a map table for the name.¶\n",
    "We saw on part 3 that we thought of a distant method. Here is the code of the distance methode we usend. The sequenceMatcher library we used check which character are used and at which positon and compute a score between two given string. What we do to use this map is the following:\n",
    "\n",
    "We first use a sequenceMatcher on every possible pair of name from both database. It look on the String and compute a ratio regarding the different character on them and their position. What we imediatly saw were:\n",
    "\n",
    "- Nearly all element having a score >90% are a perfecte match\n",
    "- Nearly half of the element having a score >80% and <90% are a match. Most of the false positive are some small name with just a word changing, and this word have similare letter than the other\n",
    "- Nearly all element having <80% aren't a match\n",
    "\n",
    "As only the small name pass the 80%, we decided to compare the word of each string on each other and compute two new scores, one for each side of verification. Those having a small name have directly a poor score and those having juste one more word or the initial still have a good score. We just had to take all the pair that have more than 80% on the 3 scores to have a very good map table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def similitude(tableOne, tableTwo):\n",
    "    #Get a new table containing only the name of university from both dataframe\n",
    "    name = pd.DataFrame()\n",
    "    name['name1'] = tableOne['title']\n",
    "    name['name2'] = tableTwo['title']\n",
    "    name = name.reset_index().drop('index',1).drop(name.index[199])\n",
    "    #name = name.drop(name.index[199])\n",
    "\n",
    "    #Compute a ratio of similarity between all possible pair of name, find the best and pair them with the ratio\n",
    "    matchName = []\n",
    "    for n in name['name1']:\n",
    "        maxRatio = -100\n",
    "        bestMatch = ''\n",
    "        for m in name['name2']:\n",
    "            if similar(n,m) > maxRatio:            \n",
    "                maxRatio = similar(n,m)\n",
    "                bestMatch = m\n",
    "        matchName.append({'ratio':maxRatio, 'name1':n, 'name2':bestMatch})\n",
    "    newName = pd.DataFrame.from_dict(matchName)\n",
    "\n",
    "    #Compute two ratio on each pair of name, regarding if each word of a pair is in the other pair's string\n",
    "    secondRatio = []\n",
    "    thirdRatio = []\n",
    "    for index, row in newName.iterrows():\n",
    "        nameOne = re.sub('[,();-]', '', row['name1']).split(' ')\n",
    "        nameTwo = re.sub('[,();-]', '', row['name2']).split(' ')\n",
    "        counter1 = 0\n",
    "        match1 = 0\n",
    "        for elem in nameOne:\n",
    "            counter1 += 1\n",
    "            if elem in nameTwo:\n",
    "                match1 += 1\n",
    "        if match1 > 0 :\n",
    "            rat1 = match1/counter1\n",
    "        else:\n",
    "            rat1 = 0\n",
    "            \n",
    "        counter2 = 0\n",
    "        match2 = 0\n",
    "        for elem in nameTwo:\n",
    "            counter2 += 1\n",
    "            if elem in nameOne:\n",
    "                match2 += 1\n",
    "        if match2 > 0 :\n",
    "            rat2 = match2/counter2\n",
    "        else:\n",
    "            rat2 = 0    \n",
    "        secondRatio.append(rat1)\n",
    "        thirdRatio.append(rat2)\n",
    "    newName['ratio2'] = secondRatio\n",
    "    newName['ratio3'] = thirdRatio\n",
    "\n",
    "    #Only hold the pair which have all ratio above 80%\n",
    "    newNamehighratio = newName.query('ratio >= 0.80 and ratio2 >= 0.80 and ratio3 >= 0.80')\n",
    "    return newNamehighratio\n",
    "\n",
    "similitude(times_rankings, rankings).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
