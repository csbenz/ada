{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "Task: Obtain the 200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the [details page](https://www.topuniversities.com/universities/ecole-polytechnique-fédérale-de-lausanne-epfl).\n",
    "Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "- Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "- Answer the previous question aggregating the data by (c) country and (d) region.\n",
    "\n",
    "Plot your data using bar charts and describe briefly what you observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of top universities to take into consideration throughout the process\n",
    "n_top = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'https://www.topuniversities.com'\n",
    "ranking_url = 'https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_keys = ['total faculty', 'inter faculty', 'total student', 'total inter']\n",
    "\n",
    "#From  a String, extract only the digits and return as an int\n",
    "def extract_int(s):\n",
    "    return int(''.join(c for c in s if c.isdigit()))\n",
    "\n",
    "# Get the details of a uni from the details page and return a dictionary containing the values for the 4 above keys\n",
    "def get_topU_details(uni_url):\n",
    "    details_url = base_url + uni_url\n",
    "    \n",
    "    r = requests.get(details_url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    # Find the divs containing the numbers in the html page\n",
    "    divs = [soup.find('div', detail_key) for detail_key in detail_keys]\n",
    "    divs = [div.find('div', class_='number') if div != None else None for div in divs]\n",
    "    numbers = [extract_int(div.text) if div != None else 0 for div in divs]\n",
    "  \n",
    "    #Finally we zip the numbers with their respective key names\n",
    "    details = dict(zip(detail_keys, numbers))\n",
    "    \n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(ranking_url)\n",
    "\n",
    "if(r.status_code != requests.codes.ok):\n",
    "    sys.exit('Could not contact webpage {0}'.format(ranking_url))\n",
    "    \n",
    "rank_data = r.json()[\"data\"][:n_top]\n",
    "\n",
    "#keys we want to extract and keep. We treat ranks differently because we have to do a special operation on them\n",
    "keys = ['title','country','region']\n",
    "\n",
    "country_to_region_map = {}\n",
    "rankings_dico = []\n",
    "for uni in rank_data:    \n",
    "    values = dict([(key, uni[key]) for key in keys if key in uni])\n",
    "    values['rank_display'] = uni['rank_display'].strip(\"=\")\n",
    "    \n",
    "    #Get the details and add them to the values\n",
    "    details = get_topU_details(uni['url'])\n",
    "    values.update(details)\n",
    "    \n",
    "    rankings_dico.append(values)\n",
    "    \n",
    "    # Build the country to region map\n",
    "    country_to_region_map[values['country']] = values['region']\n",
    "\n",
    "# We manually add two countries that are missing and that we need afterwards\n",
    "country_to_region_map['Luxembourg'] = 'Europe'\n",
    "country_to_region_map['Russian Federation'] = 'Asia'\n",
    "\n",
    "rankings = pd.DataFrame(rankings_dico)\n",
    "rankings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computes the two demanded ratios and plots the best universities in a bar chart\n",
    "def plot_top_by_ratio(rankings_df, x_title, x_key='title'):\n",
    "    #Drop any existing ratios if they exist\n",
    "    rankings_df.drop(['ratio_a','ratio_b'], errors='ignore')\n",
    "    \n",
    "    # Create new columns that containthe calculated ratios\n",
    "    rankings_df['ratio_a'] = rankings_df['total faculty'] / rankings_df['total student']\n",
    "    rankings_df['ratio_b'] = rankings_df['total inter'] / rankings_df['total student']\n",
    "\n",
    "    # Sort and keep the top 10\n",
    "    best_a = rankings_df.sort_values(by='ratio_a',ascending=False).head(10)\n",
    "    best_b = rankings_df.sort_values(by='ratio_b',ascending=False).head(10)\n",
    "\n",
    "    # Plot\n",
    "    best_a.plot(kind='bar', x=x_key, y='ratio_a', legend=None, title='Best ' + x_title + ' in term of ratio between faculty members and students')\n",
    "    best_b.plot(kind='bar', x=x_key, y='ratio_b', legend=None, title='Best ' + x_title + ' in term of ratio of international students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_by_ratio(rankings, 'universities', 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe above that the best universities for the described ratios are the California Institute of Technology and the London School of Economis and Political Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We group by country and then give to the function that will recalculate ratios and plot\n",
    "rankings_by_country = rankings.groupby('country').agg(np.sum)\n",
    "rankings_by_country.reset_index(inplace=True) \n",
    "\n",
    "plot_top_by_ratio(rankings_by_country, 'country', 'country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best countries for the described ratios are Russia and Australia, as can be seen in the graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rankings_by_region = rankings.groupby('region').agg(np.sum)\n",
    "rankings_by_region.reset_index(inplace=True) \n",
    "\n",
    "plot_top_by_ratio(rankings_by_region, 'region', 'region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning the regions, the best are Asia and Oceania respectively for the two demanded ratios. The difference of international students ratio between regions is quite large, and the results can be quite surprising: Oceania comes before Europe, and Africa before Asia, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Obtain the 200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)). Repeat the analysis of the previous point and discuss briefly what you observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_ranking_url = 'https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We repeat the same process for the Times ranking\n",
    "times_r = requests.get(times_ranking_url)\n",
    "\n",
    "if(times_r.status_code != requests.codes.ok):\n",
    "    sys.exit('Could not contact webpage {0}'.format(times_ranking_url))\n",
    "    \n",
    "times_rank_data = times_r.json()[\"data\"][:n_top]\n",
    "\n",
    "times_rankings_dico = []\n",
    "for uni in times_rank_data:\n",
    "    values = dict()\n",
    "    values['title'] = uni['name']\n",
    "    values['country'] = uni['location']\n",
    "    values['rank_display'] = uni['rank'].strip(\"=\")\n",
    "    values['region'] = country_to_region_map.get(values['country'], \"Unknown\")\n",
    "    \n",
    "    values['total student'] = extract_int(uni['stats_number_students'])\n",
    "    \n",
    "    values['total inter'] = int(values['total student'] * extract_int(uni['stats_pc_intl_students']) / 100)\n",
    "    values['total faculty'] = values['total student'] * (1.0 / float(uni['stats_student_staff_ratio']))\n",
    "    #we don't need the number of international in the faculty, and can't calculate it anyway\n",
    "    \n",
    "    times_rankings_dico.append(values)\n",
    "\n",
    "times_rankings = pd.DataFrame(times_rankings_dico)\n",
    "times_rankings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_top_by_ratio(times_rankings, 'universities', 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best unis are the Vanderbilt University and the London School of Economis and Political Science. Caltech isn't even in the first top 10, while it was first in the other ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We group by country and then give to the function that will recalculate ratios and plot\n",
    "times_rankings_by_country = times_rankings.groupby('country').agg(np.sum)\n",
    "times_rankings_by_country.reset_index(inplace=True) \n",
    "\n",
    "plot_top_by_ratio(times_rankings_by_country, 'country', 'country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best countries are Denmark and Luxembourg respectively. We see that Luxembourg is by far the first in terms of international students, which can be explained by the small number of total students in the university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rankings_by_region = times_rankings.groupby('region').agg(np.sum)\n",
    "times_rankings_by_region.reset_index(inplace=True) \n",
    "\n",
    "plot_top_by_ratio(times_rankings_by_region, 'region', 'region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best regions are Africa and Oceania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We first merge by exact corresponding uni titles, then look at the remaining ones that haven't been merged.\n",
    "merged_ranking = pd.merge(rankings, times_rankings, how='outer', on='title', indicator=True, suffixes=('_topU', '_times'))\n",
    "\n",
    "#Reorder the columns lexicographically so that corresponding columns are side-by-side for easier comparison\n",
    "merged_ranking.sort_index(axis=1, inplace=True)\n",
    "\n",
    "#print('Number of merged universities: ' + str(len(merged_ranking)) + ' / ' + str(len(rankings)))\n",
    "topU_only = merged_ranking[merged_ranking['_merge'] == 'left_only']\n",
    "times_only = merged_ranking[merged_ranking['_merge'] == 'right_only']\n",
    "both = merged_ranking[merged_ranking['_merge'] == 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topU_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that in most cases that were not merged, the uni titles have additional abbreviations, or some characters are a bit different (such as the dash in ETH Zurich). We decide to remove the special characters from the titles, make them all lowercase, and then check if the titles in each dataframe contain each other.\n",
    "\n",
    "We check if one of the normalized titles is contained in another, and if so, we consider it a match. Note that when there are multiple matches, like with 'The Chinese University of Hong Kong (CUHK)' and 'University of Hong Kong', we ignore the match, but this happens only once for all unis. We could additionally compute a difference function between the conflicting matches to resolve the issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a column 'n_title' with a lowercase-only title that was stripped of its special characters and spaces\n",
    "def add_normalize_title(df):\n",
    "    n_titles = df['title']\n",
    "    n_titles = n_titles.str.replace('[^a-zA-Z]', '')\n",
    "    n_titles = n_titles.str.lower()\n",
    "\n",
    "    df['n_title'] = n_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "add_normalize_title(topU_only)\n",
    "add_normalize_title(times_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topU_only['n_title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_title_contain(left, right):\n",
    "    for (index_topU,uni_name) in left['n_title'].iteritems():\n",
    "        contains = right['n_title'].str.contains(uni_name)\n",
    "\n",
    "        if np.sum(contains) == 1:\n",
    "            print('Found unique match! :D for ' + uni_name)\n",
    "            index_times = contains.index[contains == True].tolist()[0]\n",
    "\n",
    "            topU_part = left.loc[[index_topU]].squeeze().dropna(how='all').drop(['title'])\n",
    "            times_part = right.loc[[index_times]].squeeze().dropna(how='all')\n",
    "\n",
    "            joined = topU_part.append(times_part)\n",
    "            #print(joined)\n",
    "            joined.drop(['_merge', 'n_title'], inplace=True)\n",
    "\n",
    "            both.loc[-1] = joined\n",
    "            both.reset_index(drop=True,inplace=True)\n",
    "            both.drop('_merge', inplace=True, errors='ignore')\n",
    "            \n",
    "            left.drop(index_topU,inplace=True)\n",
    "            right.drop(index_times,inplace=True)\n",
    "\n",
    "        elif np.sum(contains) > 1:\n",
    "            print('Found multiple matches :O for ' + uni_name)\n",
    "        else:\n",
    "            print('Found no match :( for ' + uni_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_title_contain(topU_only, times_only)\n",
    "find_title_contain(times_only, topU_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topU_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = both.corr()\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "Can you find the best university taking in consideration both rankings? Explain your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the two websites we colleced our data from, we can see how they rank the universities. They take into account the number of students, the Student-to-staff ratio and the percent of international students.\n",
    "Therefore,.. TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
