{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eat the season\n",
    "get some food per season from [eat the season](http://www.eattheseasons.com/seasons.php) website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>broccoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January</td>\n",
       "      <td>broccolini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>brussels sprouts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>January</td>\n",
       "      <td>butternut squash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>January</td>\n",
       "      <td>celery root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month              food\n",
       "0  January          broccoli\n",
       "1  January        broccolini\n",
       "2  January  brussels sprouts\n",
       "3  January  butternut squash\n",
       "4  January       celery root"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eat_season_data = pd.DataFrame(columns=['month', 'food'])\n",
    "\n",
    "for month in months:\n",
    "    r = requests.get('http://www.eattheseasons.com/{0}.php'.format(month))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    food_on_month = soup.find_all('p')\n",
    "    for p in food_on_month:\n",
    "        for elem in p.text.split(\", \"):\n",
    "            if (elem.lower() != month.lower()):\n",
    "                eat_season_data = eat_season_data.append({\n",
    "                    'month': month,\n",
    "                    'food': elem.strip(),\n",
    "                }, ignore_index=True)\n",
    "\n",
    "eat_season_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seasonal food guide\n",
    "Get some food per season from [seasonal food guide](https://www.seasonalfoodguide.org/) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>food</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>late-july</td>\n",
       "      <td>Apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>early-august</td>\n",
       "      <td>Apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>late-august</td>\n",
       "      <td>Apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>early-september</td>\n",
       "      <td>Apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>late-september</td>\n",
       "      <td>Apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             month    food state\n",
       "0        late-july  Apples    AL\n",
       "1     early-august  Apples    AL\n",
       "2      late-august  Apples    AL\n",
       "3  early-september  Apples    AL\n",
       "4   late-september  Apples    AL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.seasonalfoodguide.org'\n",
    "\n",
    "bimonthly = []\n",
    "for month in months:\n",
    "    bimonthly.append('early-{0}'.format(month.lower()))\n",
    "    bimonthly.append('late-{0}'.format(month.lower()))\n",
    "\n",
    "#All the data on pages are generated by a script, let's obtain the adress\n",
    "r = requests.get('https://www.seasonalfoodguide.org/maine/late-january')\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "url_end = soup.find_all('script')[1]['src']\n",
    "req = requests.get(url + url_end)\n",
    "data = req.text\n",
    "\n",
    "season_guid_data = pd.DataFrame(columns=['month', 'food', 'state'])\n",
    "\n",
    "m = re.findall(r'\\{name:\"(.*?)\\}\\}',data)\n",
    "m = m[1:]\n",
    "\n",
    "for elem in m:\n",
    "    #get each month per states from the current eatable\n",
    "    seasons = re.findall(r'[A-Z]{2}:{seasons:\\[(.*?)\\]', elem)\n",
    "    #get each states that has some season on the current eatable\n",
    "    states = re.findall(r'([A-Z]{2}):', elem)[1:]\n",
    "    #get the name of the current eatable\n",
    "    food = re.findall(r'([A-Za-z]+)\"', elem)[0]\n",
    "    for x in range(0, len(seasons)):\n",
    "        for season in seasons[x].split(','):\n",
    "            season_guid_data = season_guid_data.append({\n",
    "                    'month' : bimonthly[int(season)-1],\n",
    "                    'food' : food,\n",
    "                    'state' : states[x]\n",
    "            \n",
    "            }, ignore_index=True)\n",
    "\n",
    "            \n",
    "#TODO: Do we need to save this dataset as a csv as it took some times to generate?\n",
    "season_guid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyse our recipies dataset\n",
    "Our dataset contains 2,5GB of html file (110'517 file regarding the number of line in the log file). There is plenty of different results. We first need to analyse what kind of data we have before analyse the data themself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log file\n",
    "We first have a log file containing valuable information. It give us the name of each file associated to the url it come from. We use it as index for the reste of the project. We will use the log file to navigate instead of looking blind in each file.\n",
    "**We saw in the logfile that some file came with some error. We keep that in mind and will come back later on it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_path = 'data/recipePages/msg.log'\n",
    "recipies_path = 'data/recipePages'\n",
    "\n",
    "f = open(log_path,'r')\n",
    "log = f.read().split('\\n')\n",
    "#TODO: Take care of the error line in the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.cooks.com/</td>\n",
       "      <td>http://www.cooks.com/rec/search/0,1-0,ground_s...</td>\n",
       "      <td>6353d9ac2c6bf20dab72ea9043cc018f.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.cooks.com/</td>\n",
       "      <td>http://www.cooks.com/rec/search/0,1-0,quick_ea...</td>\n",
       "      <td>3f207c5bffff6a090bf5a8ad9e206260.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/classic-minestrone/</td>\n",
       "      <td>7e0ad7374f08c4a8de3500c065c17180.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/Recipe/basil-butter-2/de...</td>\n",
       "      <td>4f9ea44a8519ba9d013264eb55711c9b.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.cdkitchen.com/</td>\n",
       "      <td>http://www.cdkitchen.com/recipes/recs/75/Beer_...</td>\n",
       "      <td>099aebf16685a804035fee84152c4f4f.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      domain  \\\n",
       "0      http://www.cooks.com/   \n",
       "1      http://www.cooks.com/   \n",
       "2     http://allrecipes.com/   \n",
       "3     http://allrecipes.com/   \n",
       "4  http://www.cdkitchen.com/   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.cooks.com/rec/search/0,1-0,ground_s...   \n",
       "1  http://www.cooks.com/rec/search/0,1-0,quick_ea...   \n",
       "2   http://allrecipes.com/recipe/classic-minestrone/   \n",
       "3  http://allrecipes.com/Recipe/basil-butter-2/de...   \n",
       "4  http://www.cdkitchen.com/recipes/recs/75/Beer_...   \n",
       "\n",
       "                                    file  \n",
       "0  6353d9ac2c6bf20dab72ea9043cc018f.html  \n",
       "1  3f207c5bffff6a090bf5a8ad9e206260.html  \n",
       "2  7e0ad7374f08c4a8de3500c065c17180.html  \n",
       "3  4f9ea44a8519ba9d013264eb55711c9b.html  \n",
       "4  099aebf16685a804035fee84152c4f4f.html  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data = pd.DataFrame(columns=['domain', 'url', 'file'])\n",
    "for line in log:\n",
    "    domain = re.search(r'http://.*?/', line)\n",
    "    url = re.search(r'http://.*?(?=\\t)', line)\n",
    "    file_name = re.search(r'.*?(?=\\t)', line)\n",
    "    if domain is not None:\n",
    "        if url is not None:\n",
    "            if file_name is not None:\n",
    "                log_data = log_data.append({\n",
    "                        'domain' : domain.group(0),\n",
    "                        'url' : url.group(0),\n",
    "                        'file' : file_name.group(0),\n",
    "                    }, ignore_index=True)\n",
    "\n",
    "log_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the domain name's propotion?\n",
    "As we have many different domain name, we want to know how many of each domain name we have. To see then what to do with these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "http://allrecipes.com/         28354\n",
       "http://www.food.com/           14661\n",
       "http://www.foodnetwork.com/    11996\n",
       "http://www.yummly.com/          6590\n",
       "http://www.cooks.com/           5546\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = log_data['domain'].value_counts()\n",
    "print('size: {0}'.format(df.size))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- allrecipes.com\n",
    "- www.food.com\n",
    "- www.foodnetwork.com\n",
    "\n",
    "These 3 website cover 49.77% of our dataset. We will then first make some methode to extract data from these and if needed or if we have time, we will then take care of the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the ingredients of each recipes\n",
    "We have a second dataset containing the recipe name, url, domain, ingredients and many other information. We will then extract this dataset and merge it to our log_data datafram to have the possibility to link these information to the corresponding html file. We do this because the review information we are only availible in the html file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients_list</th>\n",
       "      <th>domain</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://recipes.sparkpeople.com/recipe-detail.a...</td>\n",
       "      <td>Easy Light Chocolate Milkshake Recipe</td>\n",
       "      <td>put one half cup of milk, 4 tablespoons of cho...</td>\n",
       "      <td>http://recipes.sparkpeople.com/</td>\n",
       "      <td>d80167e4b3563a835b3dd9c916844549.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://recipes.sparkpeople.com/recipe-detail.a...</td>\n",
       "      <td>Easy Light Chocolate Milkshake Recipe</td>\n",
       "      <td>put one half cup of milk, 4 tablespoons of cho...</td>\n",
       "      <td>http://recipes.sparkpeople.com/</td>\n",
       "      <td>d80167e4b3563a835b3dd9c916844549.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.foodnetwork.com/recipes/rachael-ray...</td>\n",
       "      <td>Lamb Stew Recipe : : Recipes : Food Network</td>\n",
       "      <td>5 yellow onions|2 turnips|5 carrots|1 stalk fe...</td>\n",
       "      <td>http://www.foodnetwork.com/</td>\n",
       "      <td>b7ccedbf38fd140e814455e4838180b2.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.foodnetwork.com/recipes/paula-deen/...</td>\n",
       "      <td>Chocolate Bread Pudding Recipe : Paula Deen : ...</td>\n",
       "      <td>1 (1-pound) loaf French or Italian bread, cube...</td>\n",
       "      <td>http://www.foodnetwork.com/</td>\n",
       "      <td>2582713206ed684b355a5b2fd1629707.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.cdkitchen.com/recipes/recs/32/Snowb...</td>\n",
       "      <td>Snowball Cookies II Recipe</td>\n",
       "      <td>1/2 cup powdered sugar|1/3 cup butter or marga...</td>\n",
       "      <td>http://www.cdkitchen.com/</td>\n",
       "      <td>3ae40f3e2d60990b35030639ff8ee209.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://recipes.sparkpeople.com/recipe-detail.a...   \n",
       "1  http://recipes.sparkpeople.com/recipe-detail.a...   \n",
       "2  http://www.foodnetwork.com/recipes/rachael-ray...   \n",
       "3  http://www.foodnetwork.com/recipes/paula-deen/...   \n",
       "4  http://www.cdkitchen.com/recipes/recs/32/Snowb...   \n",
       "\n",
       "                                               title  \\\n",
       "0              Easy Light Chocolate Milkshake Recipe   \n",
       "1              Easy Light Chocolate Milkshake Recipe   \n",
       "2        Lamb Stew Recipe : : Recipes : Food Network   \n",
       "3  Chocolate Bread Pudding Recipe : Paula Deen : ...   \n",
       "4                         Snowball Cookies II Recipe   \n",
       "\n",
       "                                    ingredients_list  \\\n",
       "0  put one half cup of milk, 4 tablespoons of cho...   \n",
       "1  put one half cup of milk, 4 tablespoons of cho...   \n",
       "2  5 yellow onions|2 turnips|5 carrots|1 stalk fe...   \n",
       "3  1 (1-pound) loaf French or Italian bread, cube...   \n",
       "4  1/2 cup powdered sugar|1/3 cup butter or marga...   \n",
       "\n",
       "                            domain                                   file  \n",
       "0  http://recipes.sparkpeople.com/  d80167e4b3563a835b3dd9c916844549.html  \n",
       "1  http://recipes.sparkpeople.com/  d80167e4b3563a835b3dd9c916844549.html  \n",
       "2      http://www.foodnetwork.com/  b7ccedbf38fd140e814455e4838180b2.html  \n",
       "3      http://www.foodnetwork.com/  2582713206ed684b355a5b2fd1629707.html  \n",
       "4        http://www.cdkitchen.com/  3ae40f3e2d60990b35030639ff8ee209.html  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recip_info_path = 'data/recipeInfo/recipeInfo_WestWhiteHorvitz_WWW2013.tsv'\n",
    "\n",
    "recip_info = pd.read_csv(recip_info_path, sep='\\t', encoding='latin-1')\n",
    "\n",
    "restricted_recipe_info = recip_info[['url', 'title', 'ingredients_list']].head()\n",
    "\n",
    "result = pd.merge(restricted_recipe_info, log_data, how='inner', on='url', indicator=False, suffixes=('_info', '_log'))\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Review date\n",
    "We do **the assumption** that the people which do a recipe will review the same day or maximum in the same week he cook the recipe. We need to extract the date of all reviews to know when they cooked the recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### allrecipes.com\n",
    "Starting for allrecipes.com. An inspection on the html elements lead us to see that all review date are referenced in:\n",
    "\n",
    "```<div class=\"review\">```\n",
    "\n",
    "To find it, we used the inspector feature in firefox. It apears on testing that many html file we have are malformed. Sometime a page is just a search on a food name and it's not a recipe. Some othertime, there is no review. We had to modify the following methods manytime to take these error into account.\n",
    "As we first parcour the entire dataset to extracte the useful information, we decide to put some nul value when the data are malformed. We will also have to take care of the quantity associated to the ingredients name. But we keep it for later.\n",
    "\n",
    "We also had the surprise that BeautifulSoup search by matching element. It lead to the following problem, searching class review give us all class containging the word 'review' like 'previre' and many others. To deal with this problem and only get our class, we modify our usual way to search with BeautifulSoup and use an anonymus function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec. 22, 2003 - Dec. 2, 2005 - Sep. 30, 2007 - Jan. 29, 2003 - Dec. 28, 2006 - Oct. 6, 2006 - Dec. 12, 2005 - Jan. 29, 2003 - Feb. 1, 2007 - Jan. 29, 2003'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def allRecipesReviewDate(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    #The mentionned lamnda function for BeautifulSoup search\n",
    "    review_html = soup.find_all(lambda tag: tag.name =='div' and tag.get('class') == ['review'])\n",
    "    reviews = ''\n",
    "    for rev in review_html:\n",
    "        if rev is not None:\n",
    "            if reviews != '':\n",
    "                reviews += ' - '\n",
    "            text = rev.text.strip().replace('\\n', '').replace('\\t', '')\n",
    "            reviews += re.search(r'[A-Z][a-z]{2}\\. [0-9]*, 200[0-9]', text).group(0)\n",
    "    return reviews\n",
    "\n",
    "#Example of result with a random file on this domain\n",
    "results = allRecipesReviewDate('data/recipePages/7e0ad7374f08c4a8de3500c065c17180.html')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### www.food.com\n",
    "Same principe, we use the inspector on firefox to indentify the review date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on September 09, 2004 - on April 28, 2011 - on February 11, 2010'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fooRecipesReviewDate(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    review_html = soup.find_all(\"div\", class_=\"about-recipe-info\")\n",
    "    reviews = ''\n",
    "    for rev in review_html:\n",
    "        if rev is not None:\n",
    "            if reviews != '':\n",
    "                reviews += ' - '\n",
    "            reviews += rev.find_all('p')[1].text\n",
    "    \n",
    "    return reviews\n",
    "fooRecipesReviewDate('data/recipePages/60e9148725c3f64336fc9d83b2c1b521.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<div class=\"about-recipe-info\">\n",
    "\t\t\t\t\t<div class=\"user-info clrfix\">\n",
    "\t\t\t\t\t\t<p>By <a href=\"http://share.food.com/community/Kana/style.esi?member_id=153919\"><span itemprop=\"author\">Kana</span></a></p>\n",
    "\t\t\t\t\t\t<dl class=\"fsm\" id=\"aboutRnR0\">\n",
    "\t\t\t\t\t\t\t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<dt class=\"user-click\"><a><span></span></a></dt>\n",
    "<dd class=\"flyout fly-dd\" id=\"userFlyout\">\n",
    "\t<div class=\"fly-hd\"></div>\n",
    "\t<div class=\"fly-bd\">\n",
    "\t\t<a class=\"close\"></a>\n",
    "\t\t<h3>Select One</h3>\n",
    "\t\t<ul class=\"fly-ul\">\n",
    "\t\t\t<li class=\"fly-li\"><a href=\"http://www.food.com/mail/compose?to=153919\" class=\"contact_this_chef\">Contact This Chef</a></li>\n",
    "\t\t\t<li class=\"fly-li\"><a href=\"http://share.food.com/community/dname/style.esi?member_id=153919\">Chef's Page</a></li>\n",
    "\t\t\t<li class=\"fly-li\"><a href=\"http://www.food.com/recipes.php?chef=153919\">Chef's Recipes</a></li>\n",
    "\t\t\t<li class=\"fly-li\"><a href=\"http://share.food.com/community/dname/portfolio.esi?member_id=153919\">Chef's Photos</a></li>\n",
    "\t\t\t<li class=\"fly-li\"><a href=\"http://share.food.com/community/dname/reviews.esi?member_id=153919\">Chef's Reviews</a></li>\n",
    "\t\t\t<li class=\"fly-li\"><a href=\"http://www.food.com/cookbooks.php?mid=153919\">Chef's Cookbooks</a></li>\n",
    "\t\t\t<li class=\"fly-li\"><a href=\"http://www.food.com/menus.php?owner=153919\">Chef's Menus</a></li>\n",
    "\t\t\t<li class=\"fly-li\"><a href=\"javascript:void(0);\" class=\"add_chef_to_favorites\" id=\"favorite_chef_153919\">Add to Favorites </a></li>\n",
    "\t\t</ul>\n",
    "\t</div>\n",
    "\t<div class=\"fly-ft\"></div>\n",
    "</dd>\n",
    "\n",
    "\t\t\t\t\t\t</dl>\n",
    "\t\t\t\t\t\t<script type=\"text/javascript\" charset=\"utf-8\">\n",
    "\t\t\t\t\t\t\tSNI.RZ.CustomDropdown.init('#aboutRnR0', { recipeId: 72567 });\n",
    "\t\t\t\t\t\t</script>\n",
    "\t\t\t\t\t</div>\t\n",
    "\t\t\t\t\t<p>on <meta itemprop=\"datePublished\" content=\"September 09, 2004\">September 09, 2004</p>\n",
    "\t\t\t\t</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7e0ad7374f08c4a8de3500c065c17180.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data['file'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the date of recipe's review with season of its ingredients\n",
    "As our goal is to figure out if the foods that grow during precise natural seasons are actually eaten during that time. We have to compare the review date with the season information we got from other website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO compare the date with our seasonal information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map of the USA's States\n",
    "Having a visual representation of our work is really helpfull for basic validation on our part. It is also better to explain what we did with example. Curently it's just the USA's States, we will implement it when we will have data to inject in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usa_geojson_path = os.path.join('GeoJson', 'gz_2010_us_states_500k.json')\n",
    "usa_geojson = json.load(open(usa_geojson_path))\n",
    "\n",
    "usa_map = folium.Map(location=[48, -102], zoom_start=3)\n",
    "\n",
    "usa_states = []\n",
    "for i in usa_geojson['features']:\n",
    "    usa_states.append(i['properties']['NAME'])\n",
    "\n",
    "folium.GeoJson(usa_geojson).add_to(usa_map)\n",
    "\n",
    "#TODO: Inject usefull data in it.\n",
    "usa_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final visualisation\n",
    "We have many data, many relation. It's time to give a life to all these information! The last part will be to represente these relation as concret as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "# Old cells\n",
    "These cells are some elements we had but which took too many time to run or are code we simplify or don't use anymore.\n",
    "We don't want to delet it as we took time to write them and as we can re-use a part of them.\n",
    "\n",
    "--------------------------\n",
    "\n",
    "--------------------------\n",
    "\n",
    "--------------------------\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### allrecipes.com\n",
    "Starting for allrecipes.com. An inspection on the html elements lead us to see that all ingredient are referenced in:\n",
    "\n",
    "```<li class=\"plaincharacterwrap ingredient\">text</li>```\n",
    "\n",
    "To find it, we used the inspector feature in firefox. It apears on testing that many html file we have are malformed. Sometime a page is just a search on a food name and it's not a recipe. Some othertime, the recipe is not finish, and then the ingredient list contain some blanks. We had to modify the following methods manytime to take these error into account.\n",
    "As we first parcour the entire dataset to extracte the useful information, we decide to put some nul value when the data are malformed. We will also have to take care of the quantity associated to the ingredients name. But we keep it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicken Breast Cutlets with Artichokes and Capers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 cup whole wheat or white flour, 1/2 teaspoon salt, 1/8 teaspoon white pepper, or to taste, 1/8 teaspoon black pepper, or to taste, 2 pounds chicken breast tenderloins or strips, 2 tablespoons canola oil, 2 tablespoons extra-virgin olive oil, 2 cups chicken broth, 2 tablespoons fresh lemon juice, 1 (12 ounce) jar quartered marinated artichoke hearts, with liquid, 1/4 cup capers, 2 tablespoons butter, 1/4 cup chopped flat-leaf parsley'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def allRecipesIngredients(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    ingredients_html = soup.find_all('li', class_=\"plaincharacterwrap ingredient\")\n",
    "    title_html = soup.find_all('h1', class_='plaincharacterwrap fn')\n",
    "    #The data on allrecipes sometime are not recipes but just a search on a word\n",
    "    title = ''\n",
    "    if len(title_html) > 0:\n",
    "        title = title_html[0].find('span', class_='itemreviewed').text\n",
    "    ingredients = ''\n",
    "    for ingr in ingredients_html:\n",
    "        if ingr is not None:\n",
    "            if ingredients != '':\n",
    "                ingredients += ', '\n",
    "            ingredients += ingr.text.strip()\n",
    "    return ingredients, title\n",
    "#Example of result with a random file on this domain\n",
    "results, title= allRecipesIngredients('data/recipePages/000a3333ad24828769b6be5a5e1bdb4a.html')\n",
    "\n",
    "#TODO: Format the data to only have the name of the food\n",
    "print(title)\n",
    "results'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### www.food.com\n",
    "Same principe, we use the inspector on firefox to indentify the ingredient. But this time we had a 'span' with the name value. So we don't have the quantity to take care now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crab Quiche\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'eggs, sour cream, milk, butter, melted, all-purpose flour, salt, fresh ground pepper, crabmeat, shredded swiss cheese, chopped green onion, 9 inch pie shell, unbaked'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def foodIngredients(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    ingredients_html = soup.find_all('li', class_=\"ingredient\")\n",
    "    title_html = soup.find_all('h1', class_='fn')\n",
    "    title = ''\n",
    "    if len(title_html) > 0:\n",
    "        title = title_html[0].text\n",
    "    ingredients = ''\n",
    "    for ingr in ingredients_html:\n",
    "        if ingr.find('span', class_='name') is not None:\n",
    "            if ingredients != '':\n",
    "                ingredients += ', '        \n",
    "            ingredients += ingr.find('span', class_='name').text.strip().replace('\\n', '').replace('\\t', '')\n",
    "    return ingredients, title\n",
    "\n",
    "#Example of result with a random file on this domain\n",
    "results, title = foodIngredients('data/recipePages/60e9148725c3f64336fc9d83b2c1b521.html')\n",
    "print(title)\n",
    "results'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### www.foodnetwork.com\n",
    "Same as allrecipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roasted Sweet Potato Fries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2 large sweet potatoes, peeled, 1/4 cup freshly squeezed orange juice, 1 tablespoon vegetable oil, plus 2 teaspoons, Kosher salt and freshly ground black pepper, 1/2 teaspoon ground ginger, 1/4 teaspoon cayenne pepper, or to taste'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def foodNetworkIngredients(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    ingredients_html = soup.find_all('li', class_=\"ingredient\")\n",
    "    title_html = soup.find_all('h1', class_= 'fn')\n",
    "    title = ''\n",
    "    if len(title_html) > 0:\n",
    "        title = title_html[0].text\n",
    "    ingredients = ''\n",
    "    for ingr in ingredients_html:\n",
    "        if ingr is not None:\n",
    "            if ingredients != '':\n",
    "                ingredients += ', '\n",
    "            ingredients += ingr.text.strip()\n",
    "    return ingredients, title\n",
    "\n",
    "#Example of result with a random file on this domain\n",
    "results , title = foodNetworkIngredients('data/recipePages/10cf272724e823b8038b8190addf04d3.html')\n",
    "\n",
    "\n",
    "\n",
    "#TODO: Format the data to only have the name of the food\n",
    "print(title)\n",
    "results'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the ingredients of each recipes\n",
    "Now we can get a all the ingredients of a html file on our 3 favorite website, let's create a table with all of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"html_file_path = 'data/recipePages/'\\nrecipes_ingredient = pd.DataFrame(columns=['recipe_name', 'domain', 'file', 'ingredients'])\\nindex = 0\\nfor line in log_data['domain']:  \\n    #print(index)\\n    if line == 'http://allrecipes.com/' or line == 'http://www.food.com/' or line == 'http://www.foodnetwork.com/':\\n        ingredients = []\\n        title = ''\\n        if line == 'http://allrecipes.com/':\\n            ingredients, title = allRecipesIngredients(html_file_path + log_data['file'][index])\\n        if line == 'http://www.food.com/':\\n            ingredients, title = foodIngredients(html_file_path + log_data['file'][index])\\n        if line == 'http://www.foodnetwork.com/':\\n            ingredients, title = foodNetworkIngredients(html_file_path + log_data['file'][index])\\n        recipes_ingredient = recipes_ingredient.append({\\n                'recipe_name' : title,\\n                'domain' : line,\\n                'file' : log_data['file'][index],\\n                'ingredients' : ingredients\\n            }, ignore_index=True)\\n    index += 1\\n    \\n#TODO: Save this as a csv as it take age to compute. So we don't have to compute it again all the time.\\nrecipes_ingredient.head()\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''html_file_path = 'data/recipePages/'\n",
    "recipes_ingredient = pd.DataFrame(columns=['recipe_name', 'domain', 'file', 'ingredients'])\n",
    "index = 0\n",
    "for line in log_data['domain']:  \n",
    "    #print(index)\n",
    "    if line == 'http://allrecipes.com/' or line == 'http://www.food.com/' or line == 'http://www.foodnetwork.com/':\n",
    "        ingredients = []\n",
    "        title = ''\n",
    "        if line == 'http://allrecipes.com/':\n",
    "            ingredients, title = allRecipesIngredients(html_file_path + log_data['file'][index])\n",
    "        if line == 'http://www.food.com/':\n",
    "            ingredients, title = foodIngredients(html_file_path + log_data['file'][index])\n",
    "        if line == 'http://www.foodnetwork.com/':\n",
    "            ingredients, title = foodNetworkIngredients(html_file_path + log_data['file'][index])\n",
    "        recipes_ingredient = recipes_ingredient.append({\n",
    "                'recipe_name' : title,\n",
    "                'domain' : line,\n",
    "                'file' : log_data['file'][index],\n",
    "                'ingredients' : ingredients\n",
    "            }, ignore_index=True)\n",
    "    index += 1\n",
    "    \n",
    "#TODO: Save this as a csv as it take age to compute. So we don't have to compute it again all the time.\n",
    "recipes_ingredient.head()'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
