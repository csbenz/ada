{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eat the season\n",
    "get some food per season from [eat the season](http://www.eattheseasons.com/seasons.php) website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>broccoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January</td>\n",
       "      <td>broccolini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>brussels sprouts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>January</td>\n",
       "      <td>butternut squash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>January</td>\n",
       "      <td>celery root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month              food\n",
       "0  January          broccoli\n",
       "1  January        broccolini\n",
       "2  January  brussels sprouts\n",
       "3  January  butternut squash\n",
       "4  January       celery root"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eat_season_data = pd.DataFrame(columns=['month', 'food'])\n",
    "\n",
    "for month in months:\n",
    "    r = requests.get('http://www.eattheseasons.com/{0}.php'.format(month))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    food_on_month = soup.find_all('p')\n",
    "    for p in food_on_month:\n",
    "        for elem in p.text.split(\", \"):\n",
    "            if (elem.lower() != month.lower()):\n",
    "                eat_season_data = eat_season_data.append({\n",
    "                    'month': month.lower(),\n",
    "                    'food': elem.strip(),\n",
    "                }, ignore_index=True)\n",
    "\n",
    "eat_season_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seasonal food guide\n",
    "Get some food per season from [seasonal food guide](https://www.seasonalfoodguide.org/) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSeasonalFoodGuideCSV():\n",
    "    \n",
    "    url = 'https://www.seasonalfoodguide.org'\n",
    "\n",
    "    #All the data on pages are generated by a script, let's obtain the adress\n",
    "    r = requests.get('https://www.seasonalfoodguide.org/maine/late-january')\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    url_end = soup.find_all('script')[2]['src']\n",
    "    req = requests.get(url + url_end)\n",
    "    data = req.text\n",
    "\n",
    "    season_guid_data = pd.DataFrame(columns=['month', 'food', 'state'])\n",
    "\n",
    "    m = re.findall(r'\\{name:\"(.*?)\\}\\}',data)\n",
    "    m = m[1:]\n",
    "\n",
    "    for elem in m:\n",
    "        #get each month per states from the current eatable\n",
    "        seasons = re.findall(r'[A-Z]{2}:{seasons:\\[(.*?)\\]', elem)\n",
    "        #get each states that has some season on the current eatable\n",
    "        states = re.findall(r'([A-Z]{2}):', elem)[1:]\n",
    "        #get the name of the current eatable\n",
    "        food = re.findall(r'([A-Za-z]+)\"', elem)[0]\n",
    "        for x in range(0, len(seasons)):\n",
    "            for season in seasons[x].split(','):\n",
    "                month\n",
    "                season_guid_data = season_guid_data.append({\n",
    "                        'month' : months[int((int(season)-1)/2)].lower(),\n",
    "                        'food' : food.lower(),\n",
    "                        'state' : states[x]\n",
    "            \n",
    "                }, ignore_index=True)\n",
    "    return season_guid_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a csv dataset\n",
    "As the seasonal food guide is pretty big with the states, using regular expression in such a big file is long. We create a csv and then read it to compute the notebook faster. \n",
    "\n",
    "Regarding the space of our project, we put all the data folder into the .gitignore. Thus the first time the user compute the project, it as to generate again all the csv. This idea will be kept in all other CSV generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>food</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>july</td>\n",
       "      <td>apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>august</td>\n",
       "      <td>apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>september</td>\n",
       "      <td>apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>october</td>\n",
       "      <td>apples</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>july</td>\n",
       "      <td>apples</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month    food state\n",
       "0       july  apples    AL\n",
       "1     august  apples    AL\n",
       "3  september  apples    AL\n",
       "5    october  apples    AL\n",
       "6       july  apples    AK"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "my_file = Path(\"data/seasonalFoodGuide.csv\")\n",
    "if my_file.is_file():\n",
    "    season_guid_data = pd.read_csv('data/seasonalFoodGuide.csv')\n",
    "else:\n",
    "    season_guid_data = buildSeasonalFoodGuideCSV()\n",
    "    season_guid_data.to_csv('data/seasonalFoodGuide.csv', index=False)\n",
    "            \n",
    "season_guid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyse our recipies dataset\n",
    "Our dataset contains 2,5GB of html file (110'517 file regarding the number of line in the log file). There is plenty of different results. We first need to analyse what kind of data we have before analyse the data themself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log file\n",
    "We first have a log file containing valuable information. It give us the name of each file associated to the url it come from. We use it as index for the reste of the project. We will use the log file to navigate instead of looking blind in each file.\n",
    "**We saw in the logfile that some file came with some error. We keep that in mind and will come back later on it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = 'data/recipePages/msg.log'\n",
    "recipies_path = 'data/recipePages'\n",
    "\n",
    "f = open(log_path,'r')\n",
    "log = f.read().split('\\n')\n",
    "#TODO: Take care of the error line in the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLogData():\n",
    "    log_data = pd.DataFrame(columns=['domain', 'url', 'file'])\n",
    "    for line in log:\n",
    "        domain = re.search(r'http://(.*?)/', line)\n",
    "        url = re.search(r'http://.*?(?=\\t)', line)\n",
    "        file_name = re.search(r'.*?(?=\\t)', line)\n",
    "        if domain is not None:\n",
    "            if url is not None:\n",
    "                if file_name is not None:\n",
    "                    log_data = log_data.append({\n",
    "                            'domain' : domain.group(0),\n",
    "                            'url' : url.group(0),\n",
    "                            'file' : file_name.group(0),\n",
    "                        }, ignore_index=True)\n",
    "    return log_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.cooks.com/</td>\n",
       "      <td>http://www.cooks.com/rec/search/0,1-0,ground_s...</td>\n",
       "      <td>6353d9ac2c6bf20dab72ea9043cc018f.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.cooks.com/</td>\n",
       "      <td>http://www.cooks.com/rec/search/0,1-0,quick_ea...</td>\n",
       "      <td>3f207c5bffff6a090bf5a8ad9e206260.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/classic-minestrone/</td>\n",
       "      <td>7e0ad7374f08c4a8de3500c065c17180.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/Recipe/basil-butter-2/de...</td>\n",
       "      <td>4f9ea44a8519ba9d013264eb55711c9b.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.cdkitchen.com/</td>\n",
       "      <td>http://www.cdkitchen.com/recipes/recs/75/Beer_...</td>\n",
       "      <td>099aebf16685a804035fee84152c4f4f.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      domain  \\\n",
       "0      http://www.cooks.com/   \n",
       "1      http://www.cooks.com/   \n",
       "2     http://allrecipes.com/   \n",
       "3     http://allrecipes.com/   \n",
       "4  http://www.cdkitchen.com/   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.cooks.com/rec/search/0,1-0,ground_s...   \n",
       "1  http://www.cooks.com/rec/search/0,1-0,quick_ea...   \n",
       "2   http://allrecipes.com/recipe/classic-minestrone/   \n",
       "3  http://allrecipes.com/Recipe/basil-butter-2/de...   \n",
       "4  http://www.cdkitchen.com/recipes/recs/75/Beer_...   \n",
       "\n",
       "                                    file  \n",
       "0  6353d9ac2c6bf20dab72ea9043cc018f.html  \n",
       "1  3f207c5bffff6a090bf5a8ad9e206260.html  \n",
       "2  7e0ad7374f08c4a8de3500c065c17180.html  \n",
       "3  4f9ea44a8519ba9d013264eb55711c9b.html  \n",
       "4  099aebf16685a804035fee84152c4f4f.html  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file = Path(\"data/recipePages/log_data.csv\")\n",
    "if my_file.is_file():\n",
    "    log_data = pd.read_csv('data/recipePages/log_data.csv')\n",
    "else:\n",
    "    log_data = buildLogData()\n",
    "    log_data.to_csv('data/recipePages/log_data.csv', index=False)\n",
    "            \n",
    "log_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the domain name's propotion?\n",
    "As we have many different domain name, we want to know how many of each domain name we have. To see then what to do with these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "http://allrecipes.com/         28354\n",
       "http://www.food.com/           14661\n",
       "http://www.foodnetwork.com/    11996\n",
       "http://www.yummly.com/          6590\n",
       "http://www.cooks.com/           5546\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = log_data['domain'].value_counts()\n",
    "print('size: {0}'.format(df.size))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- allrecipes.com\n",
    "- www.food.com\n",
    "- www.foodnetwork.com\n",
    "\n",
    "These 3 website cover 49.77% of our dataset. We will then first make some methode to extract data from these and if needed or if we have time, we will then take care of the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the ingredients of each recipes\n",
    "We have a second dataset containing the recipe name, url, domain, ingredients and many other information. We will then extract this dataset and merge it to our log_data datafram to have the possibility to link these information to the corresponding html file. We do this because the review information we are only availible in the html file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/classic-minestrone/</td>\n",
       "      <td>7e0ad7374f08c4a8de3500c065c17180.html</td>\n",
       "      <td>Classic Minestrone Recipe</td>\n",
       "      <td>3 tablespoons olive oil|1 leek, sliced|2 carro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/Recipe/basil-butter-2/de...</td>\n",
       "      <td>4f9ea44a8519ba9d013264eb55711c9b.html</td>\n",
       "      <td>Basil Butter Recipe</td>\n",
       "      <td>4 cloves garlic|15 leaves fresh basil|1/2 teas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.cdkitchen.com/</td>\n",
       "      <td>http://www.cdkitchen.com/recipes/recs/75/Beer_...</td>\n",
       "      <td>099aebf16685a804035fee84152c4f4f.html</td>\n",
       "      <td>Beer Cheese Recipe #11524</td>\n",
       "      <td>1 pound mild cheddar (shredded)|1 pound extra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.foodnetwork.com/</td>\n",
       "      <td>http://www.foodnetwork.com/recipes/claire-robi...</td>\n",
       "      <td>10cf272724e823b8038b8190addf04d3.html</td>\n",
       "      <td>Roasted Sweet Potato Fries Recipe : Claire Rob...</td>\n",
       "      <td>2 large sweet potatoes, peeled|1/4 cup freshly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/dirty-martini/</td>\n",
       "      <td>856e6ca1d45014b045c1266d406f3ccf.html</td>\n",
       "      <td>Dirty Martini Recipe</td>\n",
       "      <td>6 fluid ounces vodka|1 dash dry vermouth|1 flu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        domain  \\\n",
       "0       http://allrecipes.com/   \n",
       "1       http://allrecipes.com/   \n",
       "2    http://www.cdkitchen.com/   \n",
       "3  http://www.foodnetwork.com/   \n",
       "4       http://allrecipes.com/   \n",
       "\n",
       "                                                 url  \\\n",
       "0   http://allrecipes.com/recipe/classic-minestrone/   \n",
       "1  http://allrecipes.com/Recipe/basil-butter-2/de...   \n",
       "2  http://www.cdkitchen.com/recipes/recs/75/Beer_...   \n",
       "3  http://www.foodnetwork.com/recipes/claire-robi...   \n",
       "4        http://allrecipes.com/recipe/dirty-martini/   \n",
       "\n",
       "                                    file  \\\n",
       "0  7e0ad7374f08c4a8de3500c065c17180.html   \n",
       "1  4f9ea44a8519ba9d013264eb55711c9b.html   \n",
       "2  099aebf16685a804035fee84152c4f4f.html   \n",
       "3  10cf272724e823b8038b8190addf04d3.html   \n",
       "4  856e6ca1d45014b045c1266d406f3ccf.html   \n",
       "\n",
       "                                               title  \\\n",
       "0                          Classic Minestrone Recipe   \n",
       "1                                Basil Butter Recipe   \n",
       "2                          Beer Cheese Recipe #11524   \n",
       "3  Roasted Sweet Potato Fries Recipe : Claire Rob...   \n",
       "4                               Dirty Martini Recipe   \n",
       "\n",
       "                                    ingredients_list  \n",
       "0  3 tablespoons olive oil|1 leek, sliced|2 carro...  \n",
       "1  4 cloves garlic|15 leaves fresh basil|1/2 teas...  \n",
       "2  1 pound mild cheddar (shredded)|1 pound extra ...  \n",
       "3  2 large sweet potatoes, peeled|1/4 cup freshly...  \n",
       "4  6 fluid ounces vodka|1 dash dry vermouth|1 flu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recip_info_path = 'data/recipeInfo/recipeInfo_WestWhiteHorvitz_WWW2013.tsv'\n",
    "\n",
    "recip_info = pd.read_csv(recip_info_path, sep='\\t', encoding='latin-1')\n",
    "\n",
    "restricted_recipe_info = recip_info[['url', 'title', 'ingredients_list']]\n",
    "\n",
    "merged_info = pd.merge(log_data, restricted_recipe_info, how='inner', on='url', indicator=False, suffixes=('_info', '_log'))\n",
    "merged_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the dataset\n",
    "Currently, our dataset is hudge. Going throug it completly took some time. To simplify our research acording to our previous observation, we will only keep the 3 main domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/classic-minestrone/</td>\n",
       "      <td>7e0ad7374f08c4a8de3500c065c17180.html</td>\n",
       "      <td>Classic Minestrone Recipe</td>\n",
       "      <td>3 tablespoons olive oil|1 leek, sliced|2 carro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/Recipe/basil-butter-2/de...</td>\n",
       "      <td>4f9ea44a8519ba9d013264eb55711c9b.html</td>\n",
       "      <td>Basil Butter Recipe</td>\n",
       "      <td>4 cloves garlic|15 leaves fresh basil|1/2 teas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.foodnetwork.com/</td>\n",
       "      <td>http://www.foodnetwork.com/recipes/claire-robi...</td>\n",
       "      <td>10cf272724e823b8038b8190addf04d3.html</td>\n",
       "      <td>Roasted Sweet Potato Fries Recipe : Claire Rob...</td>\n",
       "      <td>2 large sweet potatoes, peeled|1/4 cup freshly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/dirty-martini/</td>\n",
       "      <td>856e6ca1d45014b045c1266d406f3ccf.html</td>\n",
       "      <td>Dirty Martini Recipe</td>\n",
       "      <td>6 fluid ounces vodka|1 dash dry vermouth|1 flu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipes/seafood/fish/tro...</td>\n",
       "      <td>c6a40a7de4b506a935093b67bccf4aac.html</td>\n",
       "      <td>Trout Recipes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        domain  \\\n",
       "0       http://allrecipes.com/   \n",
       "1       http://allrecipes.com/   \n",
       "2  http://www.foodnetwork.com/   \n",
       "3       http://allrecipes.com/   \n",
       "4       http://allrecipes.com/   \n",
       "\n",
       "                                                 url  \\\n",
       "0   http://allrecipes.com/recipe/classic-minestrone/   \n",
       "1  http://allrecipes.com/Recipe/basil-butter-2/de...   \n",
       "2  http://www.foodnetwork.com/recipes/claire-robi...   \n",
       "3        http://allrecipes.com/recipe/dirty-martini/   \n",
       "4  http://allrecipes.com/recipes/seafood/fish/tro...   \n",
       "\n",
       "                                    file  \\\n",
       "0  7e0ad7374f08c4a8de3500c065c17180.html   \n",
       "1  4f9ea44a8519ba9d013264eb55711c9b.html   \n",
       "2  10cf272724e823b8038b8190addf04d3.html   \n",
       "3  856e6ca1d45014b045c1266d406f3ccf.html   \n",
       "4  c6a40a7de4b506a935093b67bccf4aac.html   \n",
       "\n",
       "                                               title  \\\n",
       "0                          Classic Minestrone Recipe   \n",
       "1                                Basil Butter Recipe   \n",
       "2  Roasted Sweet Potato Fries Recipe : Claire Rob...   \n",
       "3                               Dirty Martini Recipe   \n",
       "4                                      Trout Recipes   \n",
       "\n",
       "                                    ingredients_list  \n",
       "0  3 tablespoons olive oil|1 leek, sliced|2 carro...  \n",
       "1  4 cloves garlic|15 leaves fresh basil|1/2 teas...  \n",
       "2  2 large sweet potatoes, peeled|1/4 cup freshly...  \n",
       "3  6 fluid ounces vodka|1 dash dry vermouth|1 flu...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keeped_domain = pd.DataFrame({'domain':['http://allrecipes.com/', 'http://www.food.com/', 'http://www.foodnetwork.com/']})\n",
    "\n",
    "new_merged = merged_info[merged_info.domain.isin(keeped_domain.domain)].reset_index().drop('index', 1)\n",
    "new_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Review date\n",
    "We do **the assumption** that the people which do a recipe will review the same day or maximum in the same week he cook the recipe. We need to extract the date of all reviews to know when they cooked the recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### allrecipes.com\n",
    "Starting for allrecipes.com. An inspection on the html elements lead us to see that all review date are referenced in:\n",
    "\n",
    "``<div class=\"review\">``\n",
    "\n",
    "To find it, we used the inspector feature in firefox. It apears on testing that many html file we have are malformed. Sometime a page is just a search on a food name and it's not a recipe. Some othertime, there is no review. We had to modify the following methods manytime to take these error into account.\n",
    "As we first parcour the entire dataset to extracte the useful information, we decide to put some nul value when the data are malformed. We will also have to take care of the quantity associated to the ingredients name. But we keep it for later.\n",
    "\n",
    "We also had the surprise that BeautifulSoup search by matching element. It lead to the following problem, searching class review give us all class containging the word 'review' like 'previre' and many others. To deal with this problem and only get our class, we modify our usual way to search with BeautifulSoup and use an anonymus function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec. 22, 2003 - Dec. 2, 2005 - Sep. 30, 2007 - Jan. 29, 2003 - Dec. 28, 2006 - Oct. 6, 2006 - Dec. 12, 2005 - Jan. 29, 2003 - Feb. 1, 2007 - Jan. 29, 2003'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def allRecipesReviewDate(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    #The mentionned lamnda function for BeautifulSoup search\n",
    "    review_html = soup.find_all(lambda tag: tag.name =='div' and tag.get('class') == ['review'])\n",
    "    reviews = ''\n",
    "    for rev in review_html:\n",
    "        if rev is not None:\n",
    "            text = rev.text.strip().replace('\\n', '').replace('\\t', '')\n",
    "            regex = re.search(r'[A-Z][a-z]{2}\\. [0-9]*, 200[0-9]', text)\n",
    "            if regex is not None:\n",
    "                if reviews != '':\n",
    "                    reviews += ' - '            \n",
    "                reviews += regex.group(0)\n",
    "    return reviews\n",
    "\n",
    "#Example of result with a random file on this domain\n",
    "allRecipesReviewDate('data/recipePages/7e0ad7374f08c4a8de3500c065c17180.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### www.food.com\n",
    "Same principe, we use the inspector on firefox to indentify the review date. This time, there is no class easely findable directly for the date. We goes up to the first one acceptable and the  do a second find_all on it. As there is two ``<p>`` elements this time and we are interessting in the second one, we just take only the second element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on September 09, 2004 - on April 28, 2011 - on February 11, 2010'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foodReviewDate(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    review_html = soup.find_all('div', class_=\"about-recipe-info\")\n",
    "    reviews = ''\n",
    "    for rev in review_html:\n",
    "        if rev is not None:\n",
    "            if reviews != '':\n",
    "                reviews += ' - '\n",
    "            reviews += rev.find_all('p')[1].text    \n",
    "    return reviews\n",
    "foodReviewDate('data/recipePages/60e9148725c3f64336fc9d83b2c1b521.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### www.foodnetwork.com\n",
    "Same procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on January 07, 2012 - on December 22, 2011 - on November 10, 2011'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foodnetworkReviewDate(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    review_html = soup.find_all('div', class_=\"about-recipe-info\")\n",
    "    reviews = ''\n",
    "    for rev in review_html:\n",
    "        if rev is not None:\n",
    "            rev_p = rev.find_all('p')\n",
    "            if len(rev_p) >= 3:                \n",
    "                if reviews != '':\n",
    "                    reviews += ' - '\n",
    "                reviews += rev_p[2].text    \n",
    "    return reviews\n",
    "foodnetworkReviewDate('data/recipePages/10cf272724e823b8038b8190addf04d3.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the review date of each recipes\n",
    "Now we can get a all the review date of a html file on our 3 favorite website, let's create a table with all of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_review_data():\n",
    "    html_file_path = 'data/recipePages/'\n",
    "    reviews = pd.DataFrame(columns=['reviews_dates', 'domain', 'url', 'file', 'title', 'ingredients_list'])\n",
    "    index = 0\n",
    "    nbr_elem = new_merged.shape[0]\n",
    "    for line in new_merged['domain']:    \n",
    "        text = 'NaN'\n",
    "        if line == 'http://allrecipes.com/':\n",
    "            text = allRecipesReviewDate(html_file_path + new_merged['file'][index])\n",
    "        if line == 'http://www.food.com/':\n",
    "            text = foodReviewDate(html_file_path + new_merged['file'][index])\n",
    "        if line == 'http://www.foodnetwork.com/':\n",
    "            text = foodnetworkReviewDate(html_file_path + new_merged['file'][index])\n",
    "        reviews = reviews.append({\n",
    "                'reviews_dates' : text,\n",
    "                'domain' : new_merged['domain'][index],\n",
    "                'url' : new_merged['url'][index],\n",
    "                'file' : new_merged['file'][index],\n",
    "                'title' : new_merged['title'][index],\n",
    "                'ingredients_list' : new_merged['ingredients_list'][index],\n",
    "        }, ignore_index=True)\n",
    "        if ((index % 2500) == 0 and index != 0):\n",
    "            ratio = (index / nbr_elem) * 100\n",
    "            print('We are curently at ' + str(ratio) + '%')\n",
    "        index += 1\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a csv dataset\n",
    "/!\\ This methods takes hours to generate. /!\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_dates</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec. 22, 2003 - Dec. 2, 2005 - Sep. 30, 2007 -...</td>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/classic-minestrone/</td>\n",
       "      <td>7e0ad7374f08c4a8de3500c065c17180.html</td>\n",
       "      <td>Classic Minestrone Recipe</td>\n",
       "      <td>3 tablespoons olive oil|1 leek, sliced|2 carro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec. 14, 2007 - Jun. 9, 2006 - Jul. 12, 2006 -...</td>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/Recipe/basil-butter-2/de...</td>\n",
       "      <td>4f9ea44a8519ba9d013264eb55711c9b.html</td>\n",
       "      <td>Basil Butter Recipe</td>\n",
       "      <td>4 cloves garlic|15 leaves fresh basil|1/2 teas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on January 07, 2012 - on December 22, 2011 - o...</td>\n",
       "      <td>http://www.foodnetwork.com/</td>\n",
       "      <td>http://www.foodnetwork.com/recipes/claire-robi...</td>\n",
       "      <td>10cf272724e823b8038b8190addf04d3.html</td>\n",
       "      <td>Roasted Sweet Potato Fries Recipe : Claire Rob...</td>\n",
       "      <td>2 large sweet potatoes, peeled|1/4 cup freshly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun. 21, 2004 - Dec. 5, 2007 - Sep. 2, 2007 - ...</td>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/dirty-martini/</td>\n",
       "      <td>856e6ca1d45014b045c1266d406f3ccf.html</td>\n",
       "      <td>Dirty Martini Recipe</td>\n",
       "      <td>6 fluid ounces vodka|1 dash dry vermouth|1 flu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nov. 12, 2003 - Nov. 30, 2009 - Aug. 20, 2003 ...</td>\n",
       "      <td>http://allrecipes.com/</td>\n",
       "      <td>http://allrecipes.com/recipe/candied-sweet-pot...</td>\n",
       "      <td>05bd905b46dcd56e9b97268b46f05e11.html</td>\n",
       "      <td>Candied Sweet Potatoes Recipe</td>\n",
       "      <td>4 pounds sweet potatoes, quartered|1 1/4 cups ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reviews_dates  \\\n",
       "0  Dec. 22, 2003 - Dec. 2, 2005 - Sep. 30, 2007 -...   \n",
       "1  Dec. 14, 2007 - Jun. 9, 2006 - Jul. 12, 2006 -...   \n",
       "2  on January 07, 2012 - on December 22, 2011 - o...   \n",
       "3  Jun. 21, 2004 - Dec. 5, 2007 - Sep. 2, 2007 - ...   \n",
       "4  Nov. 12, 2003 - Nov. 30, 2009 - Aug. 20, 2003 ...   \n",
       "\n",
       "                        domain  \\\n",
       "0       http://allrecipes.com/   \n",
       "1       http://allrecipes.com/   \n",
       "2  http://www.foodnetwork.com/   \n",
       "3       http://allrecipes.com/   \n",
       "4       http://allrecipes.com/   \n",
       "\n",
       "                                                 url  \\\n",
       "0   http://allrecipes.com/recipe/classic-minestrone/   \n",
       "1  http://allrecipes.com/Recipe/basil-butter-2/de...   \n",
       "2  http://www.foodnetwork.com/recipes/claire-robi...   \n",
       "3        http://allrecipes.com/recipe/dirty-martini/   \n",
       "4  http://allrecipes.com/recipe/candied-sweet-pot...   \n",
       "\n",
       "                                    file  \\\n",
       "0  7e0ad7374f08c4a8de3500c065c17180.html   \n",
       "1  4f9ea44a8519ba9d013264eb55711c9b.html   \n",
       "2  10cf272724e823b8038b8190addf04d3.html   \n",
       "3  856e6ca1d45014b045c1266d406f3ccf.html   \n",
       "4  05bd905b46dcd56e9b97268b46f05e11.html   \n",
       "\n",
       "                                               title  \\\n",
       "0                          Classic Minestrone Recipe   \n",
       "1                                Basil Butter Recipe   \n",
       "2  Roasted Sweet Potato Fries Recipe : Claire Rob...   \n",
       "3                               Dirty Martini Recipe   \n",
       "4                      Candied Sweet Potatoes Recipe   \n",
       "\n",
       "                                    ingredients_list  \n",
       "0  3 tablespoons olive oil|1 leek, sliced|2 carro...  \n",
       "1  4 cloves garlic|15 leaves fresh basil|1/2 teas...  \n",
       "2  2 large sweet potatoes, peeled|1/4 cup freshly...  \n",
       "3  6 fluid ounces vodka|1 dash dry vermouth|1 flu...  \n",
       "4  4 pounds sweet potatoes, quartered|1 1/4 cups ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file = Path('data/reviews.csv')\n",
    "if my_file.is_file():\n",
    "    review_data = pd.read_csv('data/reviews.csv', encoding='latin-1')\n",
    "else:\n",
    "    review_data = build_review_data()\n",
    "    review_data[pd.notnull(review_data['ingredients_list'])].to_csv('data/reviews.csv', index=False)\n",
    "            \n",
    "#TODO: Do we need to save this dataset as a csv as it took some times to generate?\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group per month the seasonal food dataset\n",
    "Our initial dataset have row containging a month and a food. THe idea is to have a monthe and all the coresponding food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food\n",
       "almonds                [September, October, November]\n",
       "apples                 [September, October, November]\n",
       "apricots                    [May, June, July, August]\n",
       "artichoke    [April, May, August, September, October]\n",
       "arugula                          [June, July, August]\n",
       "Name: month, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eat_season_per_month = eat_season_data.groupby('food')['month'].apply(list)\n",
    "eat_season_per_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food\n",
       "apples        [july, august, september, october, november, d...\n",
       "apricots      [july, august, may, june, september, january, ...\n",
       "artichokes    [february, march, april, may, june, september,...\n",
       "arugula       [march, april, may, june, july, august, septem...\n",
       "asparagus             [march, april, may, june, february, july]\n",
       "Name: month, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_guid_no_state = season_guid_data[['month', 'food']].drop_duplicates()\n",
    "\n",
    "season_guid_per_month = season_guid_no_state.groupby('food')['month'].apply(list)\n",
    "season_guid_per_month.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the date of recipe's review with season of its ingredients\n",
    "As our goal is to figure out if the foods that grow during precise natural seasons are actually eaten during that time. We have to compare the review date with the season information we got from other website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating the recipe regarding the ingredient list\n",
    "We want to know what are the best season to eat a recipe respecting the local production. To do so, we came with the following idea. Given the ingredients on a recipe, we will take only these which exist on our seasonal dataset, and give 6 point to the month that match, and the reduce one point per distance of the good month. The addition the score and divid it by the total of found ingredients.\n",
    "First thing to do is to get for each recipe all the month for each ingredients we recognize in our seasonal dataset. And then do a rating algorithm on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_for_ingredient():\n",
    "    months_eat = pd.DataFrame(columns=['months_eat_season'])\n",
    "    months_season = pd.DataFrame(columns=['months_season_guid'])\n",
    "\n",
    "    nbr_elem = review_data.shape[0]\n",
    "\n",
    "    for i, row in review_data.iterrows():\n",
    "        month_eat_season = []\n",
    "        month_season_guid = []\n",
    "        for line in review_data['ingredients_list'][i].split('|'):\n",
    "            words = re.sub(r\"[0-9]+|\\(|\\/|\\)|,\", '', line).lower().split(' ')\n",
    "            prev_word = ''\n",
    "            comp_word = ''\n",
    "            for word in words:\n",
    "                if word != '':\n",
    "                    if prev_word != '':\n",
    "                        comp_word = prev_word + ' ' + word\n",
    "                    if word in eat_season_per_month.index:\n",
    "                        month_eat_season.append(eat_season_per_month[word])\n",
    "                    if comp_word in eat_season_per_month.index and prev_word != '':\n",
    "                        month_eat_season.append(eat_season_per_month[comp_word])\n",
    "                    if word in season_guid_per_month.index:\n",
    "                        month_season_guid.append(season_guid_per_month[word])\n",
    "                    if comp_word in season_guid_per_month.index and prev_word != '':\n",
    "                        month_season_guid.append(season_guid_per_month[comp_word])\n",
    "                    prev_word = word\n",
    "        #TODO make this generate a ranking and not this table\n",
    "        months_eat = months_eat.append({\n",
    "                    'months_eat_season' : month_eat_season,\n",
    "            }, ignore_index=True)\n",
    "        months_season = months_season.append({\n",
    "                    'months_season_guid' : month_season_guid,\n",
    "            }, ignore_index=True)\n",
    "        #if ((i % 2500) == 0):            \n",
    "        #    ratio = (i / nbr_elem) * 100\n",
    "        #    print('We are curently at ' + str(ratio) + '%')\n",
    "    return months_eat, months_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_season_guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[january, february, march, april, may, june, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[june, july, august, september, october, nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[may, june, july, august, september, october,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[september, october, november]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[may, june, july, august, september, october,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  months_season_guid\n",
       "0  [[january, february, march, april, may, june, ...\n",
       "1  [[june, july, august, september, october, nove...\n",
       "2  [[may, june, july, august, september, october,...\n",
       "3                   [[september, october, november]]\n",
       "4  [[may, june, july, august, september, october,..."
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_eat, months_season = get_month_for_ingredient()\n",
    "months_season.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_algo(data_set):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_distance(month_one, month_two):\n",
    "    month_pos = {\n",
    "        'January': 1,\n",
    "        'February': 2,\n",
    "        'March': 3,\n",
    "        'April': 4,\n",
    "        'May': 5,\n",
    "        'June': 6,\n",
    "        'July': 7,\n",
    "        'August': 8,\n",
    "        'September': 9,\n",
    "        'October': 10,\n",
    "        'November': 11,\n",
    "        'December': 12\n",
    "    }\n",
    "    diff = month_pos[month_one] - month_pos[month_two]\n",
    "    if diff < 0:\n",
    "        diff = diff * - 1\n",
    "    if diff > 6:\n",
    "        diff = (12 - diff)\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "month_distance('November','March')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map of the USA's States\n",
    "Having a visual representation of our work is really helpfull for basic validation on our part. It is also better to explain what we did with example. Curently it's just the USA's States, we will implement it when we will have data to inject in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usa_geojson_path = os.path.join('GeoJson', 'gz_2010_us_states_500k.json')\n",
    "usa_geojson = json.load(open(usa_geojson_path))\n",
    "\n",
    "usa_map = folium.Map(location=[48, -102], zoom_start=3)\n",
    "\n",
    "usa_states = []\n",
    "for i in usa_geojson['features']:\n",
    "    usa_states.append(i['properties']['NAME'])\n",
    "\n",
    "folium.GeoJson(usa_geojson).add_to(usa_map)\n",
    "\n",
    "#TODO: Inject usefull data in it.\n",
    "usa_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final visualisation\n",
    "We have many data, many relation. It's time to give a life to all these information! The last part will be to represente these relation as concret as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "--------------------------\n",
    "\n",
    "--------------------------\n",
    "\n",
    "--------------------------\n",
    "# Archive\n",
    "These cells are some elements we had but which took too many time to run or are code we simplify or don't use anymore.\n",
    "We don't want to delet it as we took time to write them and as we can re-use a part of them. We will move these away for the delivery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### allrecipes.com\n",
    "Starting for allrecipes.com. An inspection on the html elements lead us to see that all ingredient are referenced in:\n",
    "\n",
    "```<li class=\"plaincharacterwrap ingredient\">text</li>```\n",
    "\n",
    "To find it, we used the inspector feature in firefox. It apears on testing that many html file we have are malformed. Sometime a page is just a search on a food name and it's not a recipe. Some othertime, the recipe is not finish, and then the ingredient list contain some blanks. We had to modify the following methods manytime to take these error into account.\n",
    "As we first parcour the entire dataset to extracte the useful information, we decide to put some nul value when the data are malformed. We will also have to take care of the quantity associated to the ingredients name. But we keep it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''def allRecipesIngredients(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    ingredients_html = soup.find_all('li', class_=\"plaincharacterwrap ingredient\")\n",
    "    title_html = soup.find_all('h1', class_='plaincharacterwrap fn')\n",
    "    #The data on allrecipes sometime are not recipes but just a search on a word\n",
    "    title = ''\n",
    "    if len(title_html) > 0:\n",
    "        title = title_html[0].find('span', class_='itemreviewed').text\n",
    "    ingredients = ''\n",
    "    for ingr in ingredients_html:\n",
    "        if ingr is not None:\n",
    "            if ingredients != '':\n",
    "                ingredients += ', '\n",
    "            ingredients += ingr.text.strip()\n",
    "    return ingredients, title\n",
    "#Example of result with a random file on this domain\n",
    "results, title= allRecipesIngredients('data/recipePages/000a3333ad24828769b6be5a5e1bdb4a.html')\n",
    "\n",
    "#TODO: Format the data to only have the name of the food\n",
    "print(title)\n",
    "results'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### www.food.com\n",
    "Same principe, we use the inspector on firefox to indentify the ingredient. But this time we had a 'span' with the name value. So we don't have the quantity to take care now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''def foodIngredients(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    ingredients_html = soup.find_all('li', class_=\"ingredient\")\n",
    "    title_html = soup.find_all('h1', class_='fn')\n",
    "    title = ''\n",
    "    if len(title_html) > 0:\n",
    "        title = title_html[0].text\n",
    "    ingredients = ''\n",
    "    for ingr in ingredients_html:\n",
    "        if ingr.find('span', class_='name') is not None:\n",
    "            if ingredients != '':\n",
    "                ingredients += ', '        \n",
    "            ingredients += ingr.find('span', class_='name').text.strip().replace('\\n', '').replace('\\t', '')\n",
    "    return ingredients, title\n",
    "\n",
    "#Example of result with a random file on this domain\n",
    "results, title = foodIngredients('data/recipePages/60e9148725c3f64336fc9d83b2c1b521.html')\n",
    "print(title)\n",
    "results'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### www.foodnetwork.com\n",
    "Same as allrecipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''def foodNetworkIngredients(path):\n",
    "    f = open(path, 'r', encoding='latin-1')\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "    ingredients_html = soup.find_all('li', class_=\"ingredient\")\n",
    "    title_html = soup.find_all('h1', class_= 'fn')\n",
    "    title = ''\n",
    "    if len(title_html) > 0:\n",
    "        title = title_html[0].text\n",
    "    ingredients = ''\n",
    "    for ingr in ingredients_html:\n",
    "        if ingr is not None:\n",
    "            if ingredients != '':\n",
    "                ingredients += ', '\n",
    "            ingredients += ingr.text.strip()\n",
    "    return ingredients, title\n",
    "\n",
    "#Example of result with a random file on this domain\n",
    "results , title = foodNetworkIngredients('data/recipePages/10cf272724e823b8038b8190addf04d3.html')\n",
    "\n",
    "\n",
    "\n",
    "#TODO: Format the data to only have the name of the food\n",
    "print(title)\n",
    "results'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the ingredients of each recipes\n",
    "Now we can get a all the ingredients of a html file on our 3 favorite website, let's create a table with all of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''html_file_path = 'data/recipePages/'\n",
    "recipes_ingredient = pd.DataFrame(columns=['recipe_name', 'domain', 'file', 'ingredients'])\n",
    "index = 0\n",
    "for line in log_data['domain']:  \n",
    "    #print(index)\n",
    "    if line == 'http://allrecipes.com/' or line == 'http://www.food.com/' or line == 'http://www.foodnetwork.com/':\n",
    "        ingredients = []\n",
    "        title = ''\n",
    "        if line == 'http://allrecipes.com/':\n",
    "            ingredients, title = allRecipesIngredients(html_file_path + log_data['file'][index])\n",
    "        if line == 'http://www.food.com/':\n",
    "            ingredients, title = foodIngredients(html_file_path + log_data['file'][index])\n",
    "        if line == 'http://www.foodnetwork.com/':\n",
    "            ingredients, title = foodNetworkIngredients(html_file_path + log_data['file'][index])\n",
    "        recipes_ingredient = recipes_ingredient.append({\n",
    "                'recipe_name' : title,\n",
    "                'domain' : line,\n",
    "                'file' : log_data['file'][index],\n",
    "                'ingredients' : ingredients\n",
    "            }, ignore_index=True)\n",
    "    index += 1\n",
    "    \n",
    "#TODO: Save this as a csv as it take age to compute. So we don't have to compute it again all the time.\n",
    "recipes_ingredient.head()'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
